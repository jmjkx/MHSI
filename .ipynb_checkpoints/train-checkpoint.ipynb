{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue May 14 12:16:11 2019\n",
    "\n",
    "@author: viryl\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from datetime import datetime\n",
    "from ipdb import set_trace\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset as BaseDataset\n",
    "\n",
    "\n",
    "# 加载输入\n",
    "\n",
    "class MyDataset(BaseDataset):\n",
    "    \"\"\"CamVid Dataset. Read images, apply augmentation and preprocessing transformations.\n",
    "\n",
    "    Args:\n",
    "        images_dir (str): path to images folder\n",
    "        masks_dir (str): path to segmentation masks folder\n",
    "        class_values (list): values of classes to extract from segmentation mask\n",
    "        augmentation (albumentations.Compose): data transfromation pipeline\n",
    "            (e.g. flip, scale, etc.)\n",
    "        preprocessing (albumentations.Compose): data preprocessing\n",
    "            (e.g. noralization, shape manipulation, etc.)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            images_npy,\n",
    "            label_npy,\n",
    "\n",
    "           \n",
    "    ):\n",
    "\n",
    "\n",
    "        self.images = images_npy\n",
    "        self.labels = label_npy\n",
    "        self.length = images_npy.shape[0]\n",
    "        # convert str names to class values on masks\n",
    "\n",
    "\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "\n",
    "        # read data\n",
    "        image = self.images[i]\n",
    "\n",
    "        label =  self.labels[i]\n",
    "\n",
    "         \n",
    "        \n",
    "   \n",
    "        \n",
    "        \n",
    "        \n",
    "        return torch.from_numpy(image), torch.from_numpy(np.array(label))\n",
    "        \n",
    "           \n",
    "\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "# 返回一个patch 和label\n",
    "\n",
    "\n",
    "  \n",
    "    # 包含patch image和相应label的元组"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 画混淆矩阵图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def validate(net, data_loader, set_name, classes_name):\n",
    "    \"\"\"\n",
    "    对一批数据进行预测，返回混淆矩阵以及Accuracy\n",
    "    :param net:\n",
    "    :param data_loader:\n",
    "    :param set_name:  eg: 'valid' 'train' 'tesst\n",
    "    :param classes_name:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    net.eval()\n",
    "    cls_num = len(classes_name)\n",
    "    conf_mat = np.zeros([cls_num, cls_num])\n",
    "\n",
    "    for data in data_loader:\n",
    "        images, labels = data\n",
    "        if torch.cuda.is_available():\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "        outputs = net(images)\n",
    "        outputs.detach_()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        # 统计混淆矩阵\n",
    "        for i in range(len(labels)):\n",
    "            cate_i = labels[i]\n",
    "            pre_i = predicted[i]\n",
    "            conf_mat[cate_i, pre_i] += 1.0\n",
    "\n",
    "    for i in range(cls_num):\n",
    "        print('class:{:<10}, total num:{:<6}, correct num:{:<5}  Recall: {:.2%} Precision: {:.2%}'.format(\n",
    "            classes_name[i], np.sum(\n",
    "                conf_mat[i, :]), conf_mat[i, i], conf_mat[i, i] / (1 + np.sum(conf_mat[i, :])),\n",
    "            conf_mat[i, i] / (1 + np.sum(conf_mat[:, i]))))\n",
    "\n",
    "    print('{} set Accuracy:{:.2%}'.format(\n",
    "        set_name, np.trace(conf_mat) / np.sum(conf_mat)))\n",
    "\n",
    "    return conf_mat, '{:.2}'.format(np.trace(conf_mat) / np.sum(conf_mat))\n",
    "\n",
    "\n",
    "# 生成图像\n",
    "def show_confMat(confusion_mat, classes, set_name, out_dir):\n",
    "\n",
    "    # 归一化\n",
    "    confusion_mat_N = confusion_mat.copy()\n",
    "    for i in range(len(classes)):\n",
    "        confusion_mat_N[i, :] = confusion_mat[i, :] / confusion_mat[i, :].sum()\n",
    "\n",
    "    # 获取颜色\n",
    "    # 更多颜色: http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "    cmap = plt.cm.get_cmap('Greys')\n",
    "    plt.imshow(confusion_mat_N, cmap=cmap)\n",
    "    plt.colorbar()\n",
    "\n",
    "    # 设置文字\n",
    "    xlocations = np.array(range(len(classes)))\n",
    "    plt.xticks(xlocations, list(classes), rotation=60)\n",
    "    plt.yticks(xlocations, list(classes))\n",
    "    plt.xlabel('Predict label')\n",
    "    plt.ylabel('True label')\n",
    "    plt.title('Confusion_Matrix_' + set_name)\n",
    "\n",
    "    # 打印数字\n",
    "    for i in range(confusion_mat_N.shape[0]):\n",
    "        for j in range(confusion_mat_N.shape[1]):\n",
    "            plt.text(x=j, y=i, s=int(\n",
    "                confusion_mat[i, j]), va='center', ha='center', color='red', fontsize=10)\n",
    "    # 保存\n",
    "    plt.savefig(os.path.join(out_dir, 'Confusion_Matrix' + set_name + '.png'))\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=5, out_features=2048, bias=True)\n",
       "  (1): ReLU(inplace=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Sequential(\n",
    "            nn.Linear(5, 2048),\n",
    "            nn.ReLU(inplace=True),\n",
    "        ).cuda().double()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "# --------------------搭建网络--------------------------------\n",
    "\n",
    "\n",
    "def xZero(X):\n",
    "    \n",
    "    X = X.cpu()\n",
    "    newX = np.zeros(\n",
    "        (X.shape[0], X.shape[1], X.shape[2], X.shape[3]))\n",
    "    newX[:, :, int((X.shape[2]+1)/2), int((X.shape[3]+1)/2)] = X[:,\n",
    "                                                                 :, int((X.shape[2]+1)/2), int((X.shape[3]+1)/2)]\n",
    "    newX = torch.from_numpy(newX).double()\n",
    "    if torch.cuda.is_available():\n",
    "        newX = newX.cuda()\n",
    "    return newX\n",
    "\n",
    "\n",
    "\n",
    "class SeparableConv2d(nn.Module):  # Depth wise separable conv\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False):\n",
    "        # 每个input channel被自己的filters卷积操作\n",
    "        super(SeparableConv2d, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, in_channels, kernel_size,\n",
    "                               stride, padding, dilation, groups=in_channels, bias=bias)\n",
    "        self.pointwise = nn.Conv2d(\n",
    "            in_channels, out_channels, 1, 1, 0, 1, 1, bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.pointwise(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class GetNetDim(nn.Module):\n",
    "    def __init__(self):\n",
    "        nn.Module.__init__(self)\n",
    "        # in_channels,out_channels,kernel_size,stride(default:1),padding(default:0)\n",
    "        self.conv1 = torch.nn.Sequential(\n",
    "            SeparableConv2d(33, 64, 1, 1, 0),  # 1*1卷积核\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.GroupNorm(64, 64)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(33, 256, 1, 1, 0),\n",
    "            nn.GroupNorm(256, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.4),\n",
    "            SeparableConv2d(256, 256, 3, 1, 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.4),\n",
    "            SeparableConv2d(256, 128, 3, 1, 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.4),\n",
    "            SeparableConv2d(128, 64, 3, 1, 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.GroupNorm(64, 64)\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(46208, 2048),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(2048, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, 16),\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "        \n",
    " \n",
    "    def forward(self, x):\n",
    "\n",
    "        x0 = xZero(x)\n",
    "        x1 = self.conv1(x0)\n",
    "        x2 = self.conv2(x)\n",
    "       \n",
    "        x12 = torch.cat((x1, x2), 1)\n",
    "        xCat = x12.view(-1, self.numFeatures(x12))  # 特征映射一维展开\n",
    "       \n",
    "        \n",
    "        return xCat\n",
    "\n",
    "    def numFeatures(self, x):\n",
    "        size = x.size()[1:]  # 获取卷积图像的h,w,depth\n",
    "        num = 1\n",
    "        for s in size:\n",
    "            num *= s\n",
    "            # print(s)\n",
    "        return num\n",
    "\n",
    "    def init_weights(self):  # 初始化权值\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                torch.nn.init.xavier_normal_(m.weight.data)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.GroupNorm):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                torch.nn.init.normal_(m.weight.data, 0, 0.01)\n",
    "                m.bias.data.zero_()\n",
    "                \n",
    "\n",
    "\n",
    "class Net(GetNetDim):\n",
    "  \n",
    "    def __init__(self, dim): \n",
    "        # 定义全连接层维数接口\n",
    "        super().__init__()\n",
    "        # in_channels,out_channels,kernel_size,stride(default:1),padding(default:0)\n",
    "        self.conv1 = torch.nn.Sequential(\n",
    "            SeparableConv2d(33, 64, 1, 1, 0),  # 1*1卷积核\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.GroupNorm(64, 64)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(33, 256, 1, 1, 0),\n",
    "            nn.GroupNorm(256, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.4),\n",
    "            SeparableConv2d(256, 256, 3, 1, 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.4),\n",
    "            SeparableConv2d(256, 128, 3, 1, 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.4),\n",
    "            SeparableConv2d(128, 64, 3, 1, 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.GroupNorm(64, 64)\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(dim, 2048),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(2048, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, 16),\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "        \n",
    " \n",
    "    def forward(self, x):\n",
    "\n",
    "        x0 = xZero(x)\n",
    "        x1 = self.conv1(x0)\n",
    "        x2 = self.conv2(x)\n",
    "       \n",
    "        x12 = torch.cat((x1, x2), 1)\n",
    "        xCat = x12.view(-1, self.numFeatures(x12))  # 特征映射一维展开\n",
    "       \n",
    "         \n",
    "        output = self.classifier(xCat)\n",
    "       \n",
    "        return  output\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 准备数据， 划分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "import sklearn\n",
    "from sklearn.utils.random import sample_without_replacement\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --------------------加载数据---------------------\n",
    "# Indian Pines .mat文件路径(每个文件都是一个单独的类)\n",
    "\n",
    "PATCH = np.load('/home/liyuan/dataset/HSI/高光谱医学数据/00microscope medical image data/medical sample 1-3/patch/5/PATCH.npy')\n",
    "LABEL = np.load('/home/liyuan/dataset/HSI/高光谱医学数据/00microscope medical image data/medical sample 1-3/patch/5/GND.npy')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 设置样本数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = sample_without_replacement(PATCH.shape[0],17000)\n",
    "patch = PATCH[idx]\n",
    "label = LABEL[idx]\n",
    "label = label.astype('int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(patch, label, test_size=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义超参\n",
    "EPOCH = 1000\n",
    "BATCH_SIZE = 480\n",
    "classes_name = [str(c) for c in range(3)]  # 分类地物数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iiplab/ruanjian/anaconda/envs/LiYuanTorch/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Epoch[001/1000] Iteration[015/015] Loss: 0.0744 Acc:65.21%\n",
      "Valid set Accuracy:71.59%\n",
      "Training: Epoch[002/1000] Iteration[015/015] Loss: 0.0282 Acc:71.24%\n",
      "Valid set Accuracy:84.81%\n",
      "Training: Epoch[003/1000] Iteration[015/015] Loss: 0.0140 Acc:87.84%\n",
      "Valid set Accuracy:93.57%\n",
      "Training: Epoch[004/1000] Iteration[015/015] Loss: 0.0091 Acc:93.62%\n",
      "Valid set Accuracy:94.16%\n",
      "Training: Epoch[005/1000] Iteration[015/015] Loss: 0.0067 Acc:94.10%\n",
      "Valid set Accuracy:94.16%\n",
      "Training: Epoch[006/1000] Iteration[015/015] Loss: 0.0062 Acc:94.32%\n",
      "Valid set Accuracy:94.36%\n",
      "Training: Epoch[007/1000] Iteration[015/015] Loss: 0.0058 Acc:94.53%\n",
      "Valid set Accuracy:94.78%\n",
      "Training: Epoch[008/1000] Iteration[015/015] Loss: 0.0053 Acc:94.97%\n",
      "Valid set Accuracy:95.04%\n",
      "Training: Epoch[009/1000] Iteration[015/015] Loss: 0.0050 Acc:95.51%\n",
      "Valid set Accuracy:95.26%\n",
      "Training: Epoch[010/1000] Iteration[015/015] Loss: 0.0046 Acc:95.74%\n",
      "Valid set Accuracy:95.54%\n",
      "Training: Epoch[011/1000] Iteration[015/015] Loss: 0.0046 Acc:95.87%\n",
      "Valid set Accuracy:95.49%\n",
      "Training: Epoch[012/1000] Iteration[015/015] Loss: 0.0043 Acc:96.21%\n",
      "Valid set Accuracy:95.61%\n",
      "Training: Epoch[013/1000] Iteration[015/015] Loss: 0.0042 Acc:95.93%\n",
      "Valid set Accuracy:95.61%\n",
      "Training: Epoch[014/1000] Iteration[015/015] Loss: 0.0045 Acc:96.24%\n",
      "Valid set Accuracy:95.81%\n",
      "Training: Epoch[015/1000] Iteration[015/015] Loss: 0.0042 Acc:96.16%\n",
      "Valid set Accuracy:95.89%\n",
      "Training: Epoch[016/1000] Iteration[015/015] Loss: 0.0042 Acc:96.16%\n",
      "Valid set Accuracy:95.77%\n",
      "Training: Epoch[017/1000] Iteration[015/015] Loss: 0.0040 Acc:96.44%\n",
      "Valid set Accuracy:95.80%\n",
      "Training: Epoch[018/1000] Iteration[015/015] Loss: 0.0039 Acc:96.47%\n",
      "Valid set Accuracy:95.83%\n",
      "Training: Epoch[019/1000] Iteration[015/015] Loss: 0.0042 Acc:96.37%\n",
      "Valid set Accuracy:95.83%\n",
      "Training: Epoch[020/1000] Iteration[015/015] Loss: 0.0038 Acc:96.46%\n",
      "Valid set Accuracy:95.86%\n",
      "Training: Epoch[021/1000] Iteration[015/015] Loss: 0.0039 Acc:96.62%\n",
      "Valid set Accuracy:96.01%\n",
      "Training: Epoch[022/1000] Iteration[015/015] Loss: 0.0037 Acc:96.84%\n",
      "Valid set Accuracy:96.00%\n",
      "Training: Epoch[023/1000] Iteration[015/015] Loss: 0.0038 Acc:96.56%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-af866f44e1ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    129\u001b[0m                 \u001b[0mcate_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0mpre_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m                 \u001b[0mconf_mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcate_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_i\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m         print('{} set Accuracy:{:.2%}'.format(\n\u001b[1;32m    133\u001b[0m             'Valid', conf_mat.trace() / conf_mat.sum()))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorboardX import  SummaryWriter\n",
    "\n",
    "training_dataset = MyDataset(x_train, y_train)\n",
    "testing_dataset = MyDataset(x_test, y_test)\n",
    "# Data Loaders\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=training_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=testing_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# 检查cuda是否可用\n",
    "use_cuda = torch.cuda.is_available()\n",
    "# 生成log\n",
    "now_time = datetime.now()\n",
    "time_str = datetime.strftime(now_time, '%m-%d_%H-%M-%S')\n",
    "log_path = os.path.join(os.getcwd(), \"log\")\n",
    "log_dir = os.path.join(log_path, time_str)\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "writer = SummaryWriter(log_dir)\n",
    "\n",
    "\n",
    "# ---------------------查看全连接层维数--------------------------\n",
    "cnn = GetNetDim().cuda()\n",
    "cnn.init_weights()  # 初始化权值\n",
    "cnn = cnn.double()\n",
    "cnn = cnn.cuda()\n",
    "cnn.train()\n",
    "\n",
    "sample_x = torch.from_numpy(x_train[0][np.newaxis,:,:,:])\n",
    "sample_x = sample_x.cuda()\n",
    "out = cnn(sample_x)\n",
    "# 自适应计算全连接层维数\n",
    "\n",
    "\n",
    "# ---------------------搭建网络--------------------------\n",
    "cnn = Net(out.shape[1])  # 创建CNN, 输入全连接层维数\n",
    "cnn.init_weights()  # 初始化权值\n",
    "cnn = cnn.double()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --------------------设置损失函数和优化器----------------------\n",
    "optimizer = optim.Adam(cnn.parameters(), lr = 0.0001)  # lr:(default: 1e-3)优化器\n",
    "criterion = nn.CrossEntropyLoss()  # 损失函数\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "    optimizer, step_size=EPOCH/2, gamma=0.5)  # 设置学习率下降策略\n",
    "\n",
    "# --------------------训练------------------------------\n",
    " # 使用GPU\n",
    "cnn = cnn.cuda()\n",
    "for epoch in range(EPOCH):\n",
    "    loss_sigma = 0.0    # 记录一个epoch的loss之和\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    scheduler.step()  # 更新学习率\n",
    "\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        # 获取图片和标签\n",
    "        inputs, labels = data\n",
    "        if(use_cuda):\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "        optimizer.zero_grad()  # 清空梯度\n",
    "        cnn = cnn.train()\n",
    "        \n",
    "        outputs = cnn(inputs)\n",
    "       \n",
    "        loss = criterion(outputs, labels.long())\n",
    "        loss.backward()  # 反向传播\n",
    "        optimizer.step()  # 更新权值\n",
    "\n",
    "        # 统计预测信息\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += ((predicted == labels).squeeze().sum()).item()\n",
    "        loss_sigma += loss.item()\n",
    "\n",
    "        # 每 BATCH_SIZE 个 iteration 打印一次训练信息，loss为 BATCH_SIZE 个 iteration 的平均   \n",
    "    loss_avg = loss_sigma / BATCH_SIZE\n",
    "    loss_sigma = 0.0\n",
    "    print(\"Training: Epoch[{:0>3}/{:0>3}] Iteration[{:0>3}/{:0>3}] Loss: {:.4f} Acc:{:.2%}\".format(\n",
    "        epoch + 1, EPOCH, batch_idx + 1, len(train_loader), loss_avg, correct / total))\n",
    "    # 记录训练loss\n",
    "    writer.add_scalars(\n",
    "        'Loss_group', {'train_loss': loss_avg}, epoch)\n",
    "    # 记录learning rate\n",
    "    writer.add_scalar(\n",
    "        'learning rate', scheduler.get_lr()[0], epoch)\n",
    "    # 记录Accuracy\n",
    "    writer.add_scalars('Accuracy_group', {\n",
    "                       'train_acc': correct / total}, epoch)\n",
    "    # 每个epoch，记录梯度，权值\n",
    "    for name, layer in cnn.named_parameters():\n",
    "        writer.add_histogram(\n",
    "            name + '_grad', layer.grad.cpu().data.numpy(), epoch)\n",
    "        writer.add_histogram(name + '_data', layer.cpu().data.numpy(), epoch)\n",
    "\n",
    "    # ------------------------------------ 观察模型在验证集上的表现 ------------------------------------\n",
    "    if epoch % 1 == 0:\n",
    "        loss_sigma = 0.0\n",
    "        cls_num = len(classes_name)\n",
    "        conf_mat = np.zeros([cls_num, cls_num])  # 混淆矩阵\n",
    "        cnn.eval()\n",
    "        for batch_idx, data in enumerate(test_loader):\n",
    "            images, labels = data\n",
    "            if(use_cuda):\n",
    "                images, labels = images.cuda(), labels.cuda()\n",
    "            cnn = cnn.train()\n",
    "            outputs = cnn(images)  # forward\n",
    "           \n",
    "            outputs.detach_()  # 不求梯度\n",
    "            loss = criterion(outputs, labels.long())  # 计算loss\n",
    "            loss_sigma += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)  # 统计\n",
    "            # labels = labels.data    # Variable --> tensor\n",
    "            # 统计混淆矩阵\n",
    "            for j in range(len(labels)):\n",
    "                \n",
    "                \n",
    "                cate_i = labels[j]\n",
    "                pre_i = predicted[j]\n",
    "                conf_mat[cate_i, pre_i] += 1.0\n",
    "        print('{} set Accuracy:{:.2%}'.format(\n",
    "            'Valid', conf_mat.trace() / conf_mat.sum()))\n",
    "        # 记录Loss, accuracy\n",
    "        writer.add_scalars(\n",
    "            'Loss_group', {'valid_loss': loss_sigma / len(test_loader)}, epoch)\n",
    "        writer.add_scalars('Accuracy_group', {\n",
    "                           'valid_acc': conf_mat.trace() / conf_mat.sum()}, epoch)\n",
    "print('Finished Training')\n",
    "\n",
    "# ----------------------- 保存模型 并且绘制混淆矩阵图 -------------------------\n",
    "cnn_save_path = os.path.join(log_dir, 'net_params.pkl')\n",
    "torch.save(cnn.state_dict(), cnn_save_path)\n",
    "\n",
    "conf_mat_train, train_acc = validate(cnn, train_loader, 'train', classes_name)\n",
    "conf_mat_valid, valid_acc = validate(cnn, test_loader, 'test', classes_name)\n",
    "\n",
    "show_confMat(conf_mat_train, classes_name, 'train', log_dir)\n",
    "show_confMat(conf_mat_valid, classes_name, 'valid', log_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 画模型图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from graphviz import Digraph\n",
    "\n",
    "def make_dot(var, params=None):\n",
    "    \"\"\"\n",
    "    画出 PyTorch 自动梯度图 autograd graph 的 Graphviz 表示.\n",
    "    蓝色节点表示有梯度计算的变量Variables;\n",
    "    橙色节点表示用于 torch.autograd.Function 中的 backward 的张量 Tensors.\n",
    "\n",
    "    Args:\n",
    "        var: output Variable\n",
    "        params: dict of (name, Variable) to add names to node that\n",
    "            require grad (TODO: make optional)\n",
    "    \"\"\"\n",
    "    if params is not None:\n",
    "        assert all(isinstance(p, Variable) for p in params.values())\n",
    "        param_map = {id(v): k for k, v in params.items()}\n",
    "\n",
    "    node_attr = dict(style='filled', shape='box', align='left',\n",
    "                              fontsize='12', ranksep='0.1', height='0.2')\n",
    "    dot = Digraph(node_attr=node_attr, graph_attr=dict(size=\"12,12\"))\n",
    "    seen = set()\n",
    "\n",
    "    def size_to_str(size):\n",
    "        return '(' + (', ').join(['%d' % v for v in size]) + ')'\n",
    "\n",
    "    output_nodes = (var.grad_fn,) if not isinstance(var, tuple) else tuple(v.grad_fn for v in var)\n",
    "\n",
    "    def add_nodes(var):\n",
    "        if var not in seen:\n",
    "            if torch.is_tensor(var):\n",
    "                # note: this used to show .saved_tensors in pytorch0.2, but stopped\n",
    "                # working as it was moved to ATen and Variable-Tensor merged\n",
    "                dot.node(str(id(var)), size_to_str(var.size()), fillcolor='orange')\n",
    "            elif hasattr(var, 'variable'):\n",
    "                u = var.variable\n",
    "                name = param_map[id(u)] if params is not None else ''\n",
    "                node_name = '%s\\n %s' % (name, size_to_str(u.size()))\n",
    "                dot.node(str(id(var)), node_name, fillcolor='lightblue')\n",
    "            elif var in output_nodes:\n",
    "                dot.node(str(id(var)), str(type(var).__name__), fillcolor='darkolivegreen1')\n",
    "            else:\n",
    "                dot.node(str(id(var)), str(type(var).__name__))\n",
    "            seen.add(var)\n",
    "            if hasattr(var, 'next_functions'):\n",
    "                for u in var.next_functions:\n",
    "                    if u[0] is not None:\n",
    "                        dot.edge(str(id(u[0])), str(id(var)))\n",
    "                        add_nodes(u[0])\n",
    "            if hasattr(var, 'saved_tensors'):\n",
    "                for t in var.saved_tensors:\n",
    "                    dot.edge(str(id(t)), str(id(var)))\n",
    "                    add_nodes(t)\n",
    "\n",
    "    # 多输出场景 multiple outputs\n",
    "    if isinstance(var, tuple):\n",
    "        for v in var:\n",
    "            add_nodes(v.grad_fn)\n",
    "    else:\n",
    "        add_nodes(var.grad_fn)\n",
    "    return dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Digraph.gv.pdf'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchviz import make_dot\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "x = Variable(torch.randn(1,33,5,5).double().cuda())\n",
    "\n",
    "vis_graph = make_dot(cnn(x), params=dict(cnn.named_parameters()))\n",
    "vis_graph.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
